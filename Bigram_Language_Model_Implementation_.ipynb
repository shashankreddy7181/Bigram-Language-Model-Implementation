{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "273fac08",
        "outputId": "85a51f02-0d92-49bb-8834-18468c0a19dd"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# corpus\n",
        "corpus = [\n",
        "    ['<s>', 'I', 'love', 'NLP', '</s>'],\n",
        "    ['<s>', 'I', 'love', 'deep', 'learning', '</s>'],\n",
        "    ['<s>', 'deep', 'learning', 'is', 'fun', '</s>']\n",
        "]\n",
        "\n",
        "# 1. Compute unigram and bigram counts\n",
        "unigram_counts = {}\n",
        "bigram_counts = {}\n",
        "\n",
        "for sentence in corpus:\n",
        "    for word in sentence:\n",
        "        unigram_counts[word] = unigram_counts.get(word, 0) + 1\n",
        "\n",
        "    for i in range(len(sentence) - 1):\n",
        "        w1 = sentence[i]\n",
        "        w2 = sentence[i+1]\n",
        "        bigram = (w1, w2)\n",
        "        bigram_counts[bigram] = bigram_counts.get(bigram, 0) + 1\n",
        "\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.items():\n",
        "    print(f\"{word} : {count}\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"Bigram Counts:\")\n",
        "for bigram, count in bigram_counts.items():\n",
        "    print(f\"{bigram} : {count}\")\n",
        "print(\"\")\n",
        "\n",
        "# 2. Estimate bigram probabilities using MLE\n",
        "bigram_probs = {}\n",
        "\n",
        "for bigram, count in bigram_counts.items():\n",
        "    w1 = bigram[0]\n",
        "    unigram_count_w1 = unigram_counts.get(w1, 0)\n",
        "    if unigram_count_w1 > 0:\n",
        "        bigram_probs[bigram] = count / unigram_count_w1\n",
        "    else:\n",
        "        bigram_probs[bigram] = 0.0\n",
        "\n",
        "print(\"Bigram Probabilities (MLE):\")\n",
        "for bigram, prob in bigram_probs.items():\n",
        "    print(f\"{bigram} : {prob:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "# 3. Implement a function that calculates the probability of any given sentence\n",
        "def calculate_sentence_probability(sentence, bigram_probs):\n",
        "    probability = 1.0\n",
        "    for i in range(len(sentence) - 1):\n",
        "        w1 = sentence[i]\n",
        "        w2 = sentence[i+1]\n",
        "        bigram = (w1, w2)\n",
        "        bigram_p = bigram_probs.get(bigram, 0.0)\n",
        "\n",
        "        if bigram_p == 0.0:\n",
        "            return 0.0\n",
        "\n",
        "        probability *= bigram_p\n",
        "    return probability\n",
        "\n",
        "# 4. Test your function on both sentences and print preferences\n",
        "sentence1 = ['<s>', 'I', 'love', 'NLP', '</s>']\n",
        "sentence2 = ['<s>', 'I', 'love', 'deep', 'learning', '</s>']\n",
        "\n",
        "prob1 = calculate_sentence_probability(sentence1, bigram_probs)\n",
        "prob2 = calculate_sentence_probability(sentence2, bigram_probs)\n",
        "\n",
        "print(\"Sentence Probabilities:\")\n",
        "print(f\"P(S1) = {prob1}\")\n",
        "print(f\"P(S2) = {prob2}\")\n",
        "print(\"\")\n",
        "\n",
        "if prob1 > prob2:\n",
        "    print(f\"Model prefers S1 because it has higher probability.\")\n",
        "elif prob2 > prob1:\n",
        "    print(f\"Model prefers S2 because it has higher probability.\")\n",
        "else:\n",
        "    print(\"The model assigns equal probability to both sentences.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "<s> : 3\n",
            "I : 2\n",
            "love : 2\n",
            "NLP : 1\n",
            "</s> : 3\n",
            "deep : 2\n",
            "learning : 2\n",
            "is : 1\n",
            "fun : 1\n",
            "\n",
            "Bigram Counts:\n",
            "('<s>', 'I') : 2\n",
            "('I', 'love') : 2\n",
            "('love', 'NLP') : 1\n",
            "('NLP', '</s>') : 1\n",
            "('love', 'deep') : 1\n",
            "('deep', 'learning') : 2\n",
            "('learning', '</s>') : 1\n",
            "('<s>', 'deep') : 1\n",
            "('learning', 'is') : 1\n",
            "('is', 'fun') : 1\n",
            "('fun', '</s>') : 1\n",
            "\n",
            "Bigram Probabilities (MLE):\n",
            "('<s>', 'I') : 0.667\n",
            "('I', 'love') : 1.000\n",
            "('love', 'NLP') : 0.500\n",
            "('NLP', '</s>') : 1.000\n",
            "('love', 'deep') : 0.500\n",
            "('deep', 'learning') : 1.000\n",
            "('learning', '</s>') : 0.500\n",
            "('<s>', 'deep') : 0.333\n",
            "('learning', 'is') : 0.500\n",
            "('is', 'fun') : 1.000\n",
            "('fun', '</s>') : 1.000\n",
            "\n",
            "Sentence Probabilities:\n",
            "P(S1) = 0.3333333333333333\n",
            "P(S2) = 0.16666666666666666\n",
            "\n",
            "Model prefers S1 because it has higher probability.\n"
          ]
        }
      ]
    }
  ]
}